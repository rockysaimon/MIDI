{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord, stream\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Función para cargar y procesar archivos MIDI en secuencias de notas\n",
    "def load_midi_files(data_path):\n",
    "    notes = []\n",
    "    for artist_folder in os.listdir(data_path):\n",
    "        artist_path = os.path.join(data_path, artist_folder)\n",
    "        for midi_file in os.listdir(artist_path):\n",
    "            midi_path = os.path.join(artist_path, midi_file)\n",
    "            try:\n",
    "                midi_data = converter.parse(midi_path)\n",
    "                parts = instrument.partitionByInstrument(midi_data)\n",
    "                notes_in_song = []\n",
    "                for part in parts.parts:\n",
    "                    if 'Piano' in str(part):  # Filtrar partes de piano\n",
    "                        for element in part.flat.notes:\n",
    "                            if isinstance(element, note.Note):  # Notas individuales\n",
    "                                notes_in_song.append(str(element.pitch))\n",
    "                            elif isinstance(element, chord.Chord):  # Acordes\n",
    "                                notes_in_song.append('.'.join(str(n.pitch) for n in element.notes))\n",
    "                if notes_in_song:\n",
    "                    notes.append(notes_in_song)\n",
    "            except Exception as e:\n",
    "                print(f\"Error al cargar {midi_path}: {e}\")\n",
    "                continue\n",
    "    return notes\n",
    "\n",
    "# Cargar datos MIDI\n",
    "#data_path = \"midi\"\n",
    "#notes = load_midi_files(data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, sequence_length):\n",
    "    unique_notes = sorted(set(item for song in notes for item in song))\n",
    "    note_to_int = {note: num for num, note in enumerate(unique_notes)}\n",
    "\n",
    "    X, y = [], []\n",
    "    for song in notes:\n",
    "        for i in range(len(song) - sequence_length):\n",
    "            X.append([note_to_int[note] for note in song[i:i+sequence_length]])\n",
    "            y.append(note_to_int[song[i+sequence_length]])\n",
    "\n",
    "    n_vocab = len(unique_notes)\n",
    "    X = np.reshape(X, (len(X), sequence_length, 1))\n",
    "    X = X / n_vocab  # Normalización\n",
    "    y = to_categorical(y, num_classes=n_vocab)\n",
    "\n",
    "    return X, y, unique_notes, note_to_int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(sequence_length, n_vocab):\n",
    "    model = Sequential([\n",
    "        LSTM(512, input_shape=(sequence_length, 1), return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(512, return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(512),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(n_vocab, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Loss')\n",
    "    plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "    plt.title('Model Performance')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_melody(model, start_sequence, int_to_note, melody_length=100):\n",
    "    melody = start_sequence[:]\n",
    "    for _ in range(melody_length):\n",
    "        input_sequence = np.reshape(melody[-sequence_length:], (1, sequence_length, 1))\n",
    "        prediction = model.predict(input_sequence, verbose=0)\n",
    "        next_index = np.argmax(prediction)\n",
    "        melody.append(next_index)\n",
    "    return [int_to_note[i] for i in melody]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_melody_to_midi(melody, filename):\n",
    "    output_notes = []\n",
    "    for item in melody:\n",
    "        if '.' in item or item.isdigit():\n",
    "            notes_in_chord = item.split('.')\n",
    "            chord_notes = [note.Note(n) for n in notes_in_chord]\n",
    "            for n in chord_notes:\n",
    "                n.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(chord.Chord(chord_notes))\n",
    "        else:\n",
    "            n = note.Note(item)\n",
    "            n.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(n)\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp=filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"midi\"\n",
    "notes = load_midi_files(data_path)\n",
    "\n",
    "sequence_length = 50\n",
    "X, y, unique_notes, note_to_int = prepare_sequences(notes, sequence_length)\n",
    "int_to_note = {num: note for note, num in note_to_int.items()}\n",
    "\n",
    "model = build_model(sequence_length, len(unique_notes))\n",
    "history = model.fit(X, y, epochs=50, batch_size=64)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_sequence = [note_to_int[note] for note in notes[0][:sequence_length]]\n",
    "generated_melody = generate_melody(model, start_sequence, int_to_note)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_melody_to_midi(generated_melody, \"generated_music.mid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
